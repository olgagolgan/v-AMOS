{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final report, v-AMOS Team\n",
    "\n",
    "## Introduction\n",
    "The following notebook is intended as a report for the final project of the course \"Data Science\" (Prof. Peroni), consisting in a Python query processor for graph and relational databases. It was developed by the team \"v-AMOS\", composed by four students of the MA \"Digital Humanities and Digital Humanities\" at University of Bologna: [Amelia Lamaregese](mailto:amelia.lamargese@studio.unibo.it), [Olga Pagnotta](mailto:olga.pagnotta@studio.unibo.it), [Manuele Veggi](mailto:manuele.veggi@studio.unibo.it) e [Sara Vellone](mailto:sara.vellone@studio.unibo.it).\n",
    "\n",
    "The specific guidelines of the project are available at the following [page](https://github.com/comp-data/2021-2022/tree/main/docs/project). \n",
    "\n",
    "![workflow](imgJupiNB/workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model\n",
    "\n",
    "The databases contain information on different academic publications. The entirety of the pieces of information provided can be organized within a data model and graphically visualized through UML.\n",
    "\n",
    "![classes data model](imgJupiNB/umlClasses.png)\n",
    "\n",
    "One of the first task hence concerned the translation of the model into a proper Python code. Following the syntax of classes declaration, we started defining properties and methods *IdentifiableEntity*, as all the other classes are its subclasses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentifiableEntity:\n",
    "    def __init__(self, identifier):\n",
    "        self.identifier = identifier\n",
    "\n",
    "    def getIds(self):\n",
    "        return list(self.identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on, we proceeded the subclasses *Person* and *Organization*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person(IdentifiableEntity):\n",
    "    def __init__(self, identifier, givenName, familyName):\n",
    "        super().__init__(identifier)\n",
    "        self.givenName = givenName\n",
    "        self.familyName = familyName\n",
    "\n",
    "    def getGivenName(self):\n",
    "        return self.givenName\n",
    "\n",
    "    def getFamilyName(self):\n",
    "        return self.familyName\n",
    "\n",
    "\n",
    "class Organization(IdentifiableEntity):\n",
    "    def __init__(self, identifier, name):\n",
    "        super().__init__(identifier)\n",
    "        self.name = name\n",
    "\n",
    "    def getName(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also defined *Publication* and its subclasses (*JournalArticle*, *BookChapter*, *ProceedingsPaper*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Publication(IdentifiableEntity):\n",
    "    def __init__(self, identifier, publicationYear, title, cited, authors, publicationVenue):\n",
    "        super().__init__(identifier)\n",
    "        self.publicationYear = publicationYear\n",
    "        self.title = title\n",
    "        self.cited = cited\n",
    "        self.authors = authors\n",
    "        self.publicationVenue = publicationVenue\n",
    "\n",
    "    def getPublicationYear(self):\n",
    "        return self.publicationYear\n",
    "\n",
    "    def getTitle(self):\n",
    "        return self.title\n",
    "\n",
    "    def getCitedPublications(self):\n",
    "        return self.cited \n",
    "\n",
    "    def getPublicationVenue(self):\n",
    "        return self.publicationVenue\n",
    "\n",
    "    def getAuthors(self):\n",
    "        return self.authors  \n",
    "\n",
    "\n",
    "class JournalArticle(Publication):\n",
    "    def __init__(self, identifier, publicationYear, title, cited, authors, publicationVenue, issue, volume):\n",
    "        super().__init__(identifier, publicationYear, title, cited, authors, publicationVenue)\n",
    "        self.issue = issue\n",
    "        self.volume = volume\n",
    "\n",
    "    def getIssue(self):\n",
    "        return self.issue\n",
    "\n",
    "    def getVolume(self):\n",
    "        return self.volume\n",
    "\n",
    "\n",
    "class BookChapter(Publication):\n",
    "    def __init__(self, identifier, publicationYear, title, cited, authors, publicationVenue, chapterNumber):\n",
    "        super().__init__(identifier, publicationYear, title, cited, authors, publicationVenue)\n",
    "        self.chapterNumber = chapterNumber\n",
    "\n",
    "    def getChapterNumber(self):\n",
    "        return self.chapterNumber\n",
    "\n",
    "\n",
    "class ProceedingsPaper(Publication):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we declared *Venue* and the subclasses *Journal*, *Book* and *Proceedings*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Venue(IdentifiableEntity):\n",
    "    def __init__(self, identifier, title, publisher):\n",
    "        super().__init__(identifier)\n",
    "        self.title = title\n",
    "        self.publisher = publisher\n",
    "\n",
    "    def getTitle(self):\n",
    "        return self.title\n",
    "\n",
    "    def getPublisher(self):\n",
    "        return self.publisher\n",
    "\n",
    "\n",
    "class Journal(Venue):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Book(Venue):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Proceedings(Venue):\n",
    "    def __init__(self, identifier, title, publisher, event):\n",
    "        super().__init__(identifier, title, publisher)\n",
    "        self.event = event\n",
    "\n",
    "    def getEvent(self):\n",
    "        return self.event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional classes\n",
    "\n",
    "The classes defining the functioning of the query processor have been described in the following UML model:\n",
    "\n",
    "![imgJupiNB/umlQueryPro.png](imgJupiNB/umlQueryPro.png)\n",
    "\n",
    "To complete the transaltion in Python, the workload was splitted in two halves: firstly, the creation and the query software for the relational database was created, then the same functionalities was adapted to the graph database. \n",
    "\n",
    "### Relational database\n",
    "\n",
    "The handling of the relational database is handled by the the class **RelationalProcessor** and its two subclasses, *RelationalDataProcessor* and *RelationalProcessor*. The former one is defined through file path (below mentioned as *dbPath*) and by the two methods *getdbPath* and *setdbPath* and has been defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationalProcessor:\n",
    "    def __init__(self, dbPath):\n",
    "        self.dbPath = dbPath\n",
    "\n",
    "    def getDbPath(self):  \n",
    "        return self.dbPath\n",
    "\n",
    "    def setDbPath(self, path):\n",
    "        if path != '': \n",
    "            self.dbPath = path\n",
    "            return True \n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subclass **RelationalDataProcessor** is encharged of the creation of the database starting from the two input files. Given that these two inputs can be either in CSV or JSON format, the method *uploadData* needs to be modeled in two halves, one of each focused on the treatment of a specific file format. These first lines commit to *dbPath* the dataframe *General*, populated with the entries of CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationalDataProcessor(RelationalProcessor):\n",
    "    def __init__(self, dbPath):\n",
    "      super().__init__(dbPath)\n",
    "\n",
    "    def uploadData(self, path):\n",
    "        if path != '':\n",
    "            if path.endswith(\".csv\"):\n",
    "                with connect(self.dbPath) as con:\n",
    "                    CSVDf = read_csv(path, keep_default_na=False)\n",
    "                    CSVDf.to_sql(\"General\", con, if_exists=\"replace\", index=False)\n",
    "                    con.commit()\n",
    "                    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the contrary, the JSON file has a very complex and nested structure. It is hence difficult to visualize simultaneously all the information in a sole table. The four main keys (`\"authors\"`, `\"venues_id\"`, `\"references\"` and `\"publishers\"`) allow to create four distinct dataframe and each of them has been populated with an *ad hoc* algorithm, able to take into account the peculiarities of the considered dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            elif path.endswith(\".json\"):\n",
    "                with connect(self.dbPath) as con:\n",
    "                    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        json_doc = load(f)\n",
    "\n",
    "                    # ========== AUTHOR and PUBLICATION =======\n",
    "                    authors = json_doc['authors']\n",
    "                    rows_author = []\n",
    "                    rows_first = []\n",
    "                    for doi in authors:\n",
    "                        data_row = authors[doi]\n",
    "                        for row in data_row:\n",
    "                            rows_author.append(row)\n",
    "                        for id in range(len(authors[doi])):\n",
    "                            row = [doi, id+1]\n",
    "                            rows_first.append(row)\n",
    "                    df1 = pd.DataFrame(rows_author)\n",
    "                    df2 = pd.DataFrame(rows_first); df2.columns = [\"doi\", \"coauthor no.\"]\n",
    "                    author_pubDf = df2.join(df1)\n",
    "                    author_pubDf.to_sql(\"Author\", con, if_exists=\"replace\", index=False)\n",
    "\n",
    "                    # ========== VENUES =======================  \n",
    "                    venues = json_doc['venues_id']\n",
    "                    rows_ven = []\n",
    "                    rows_first = []\n",
    "                    for doi in venues:\n",
    "                        data_row = venues[doi]\n",
    "                        for idx, item_row in enumerate(data_row): \n",
    "                            rows_ven.append(item_row)\n",
    "                            idno = idx + 1\n",
    "                            row = [doi, idno]\n",
    "                            rows_first.append(row)\n",
    "                    df1 = pd.DataFrame(rows_ven); df1.columns = [\"id\"]\n",
    "                    df2 = pd.DataFrame(rows_first); df2.columns = [\"doi\", \"id no.\"]\n",
    "                    venueDf = df2.join(df1)\n",
    "                    venueDf.to_sql(\"Venue\", con, if_exists=\"replace\", index=False)\n",
    "\n",
    "                    # ========== REFERENCES ===================\n",
    "                    references = json_doc['references']\n",
    "                    rows_ref = []\n",
    "                    rows_first = []\n",
    "                    for doi in references:\n",
    "                        data_row = references[doi]\n",
    "                        for row in data_row:\n",
    "                            rows_ref.append(row)\n",
    "                        for id in range(len(references[doi])):\n",
    "                            row = [doi, id]\n",
    "                            rows_first.append(row)\n",
    "                    df1 = pd.DataFrame(rows_ref); df1.columns = [\"doi mention\"]\n",
    "                    df2 = pd.DataFrame(rows_first); df2.columns = [\"doi\", \"reference no.\"]\n",
    "                    refDf = df2.join(df1)\n",
    "                    refDf.to_sql(\"References\", con, if_exists=\"replace\", index=False)\n",
    "                    \n",
    "                    # ========== PUBLISHERS ===================\n",
    "                    publishers = json_doc['publishers']\n",
    "                    rowsID = []\n",
    "                    rowsName = []\n",
    "                    for cross_ref in publishers:\n",
    "                        data_row = publishers[cross_ref]\n",
    "                        rowsID.append(data_row[\"id\"])\n",
    "                        rowsName.append(data_row[\"name\"])\n",
    "                    data_tuples = list(zip(rowsID,rowsName))\n",
    "                    publisherDf = pd.DataFrame(data_tuples, columns=['id','name'])\n",
    "                    publisherDf.to_sql(\"Publisher\", con, if_exists=\"replace\", index=False)\n",
    "                    con.commit()\n",
    "                    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
